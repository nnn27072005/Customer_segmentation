import streamlit as st
import pandas as pd
import numpy as np
import joblib
import plotly.express as px
from scipy.stats import boxcox

# --- C·∫§U H√åNH ---
st.set_page_config(page_title="Customer Segmentation App", layout="wide")

# --- LOAD MODEL & RESOURCES ---
@st.cache_resource
def load_resources():
    try:
        # Load g√≥i model ƒë√£ l∆∞u t·ª´ notebook
        package = joblib.load('../models/final_model.pkl')
        
        # Load th√™m Scaler (V√¨ trong cluster_lib scaler kh√¥ng n·∫±m trong analyzer, 
        # ta c·∫ßn file n√†y. N·∫øu b·∫°n ch∆∞a c√≥ file n√†y, xem ph·∫ßn L∆ØU √ù b√™n d∆∞·ªõi)
        try:
            scaler = joblib.load('../data/processed/scaler.pkl') # Ho·∫∑c ƒë∆∞·ªùng d·∫´n n∆°i b·∫°n l∆∞u scaler
        except:
            # N·∫øu kh√¥ng t√¨m th·∫•y scaler c≈©, ta t·∫°o scaler m·ªõi (ch·ªâ ƒë·ªÉ demo kh√¥ng b·ªã crash, 
            # nh∆∞ng t·ªët nh·∫•t l√† b·∫°n n√™n copy file scaler.pkl v√†o c√πng folder)
            from sklearn.preprocessing import StandardScaler
            scaler = StandardScaler()
            
        return package, scaler
    except FileNotFoundError:
        return None, None

model_package, scaler = load_resources()

if model_package is None:
    st.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file 'final_model.pkl'. H√£y ch·∫°y ƒëo·∫°n code l∆∞u model ·ªü notebook tr∆∞·ªõc!")
    st.stop()

# Tr√≠ch xu·∫•t th√†nh ph·∫ßn
kmeans = model_package['model']
pca = model_package['pca']
feature_names = model_package['features']
cluster_desc = model_package['cluster_desc']

# --- GIAO DI·ªÜN ---
st.title("üìä D·ª± ƒëo√°n Ph√¢n kh√∫c Kh√°ch h√†ng")
st.markdown("Nh·∫≠p c√°c ch·ªâ s·ªë h√†nh vi kh√°ch h√†ng ƒë·ªÉ ph√¢n lo·∫°i.")

# T·∫°o 2 c·ªôt giao di·ªán
col1, col2 = st.columns([1, 2])

with col1:
    st.subheader("Nh·∫≠p li·ªáu")
    input_data = {}
    
    # T·∫°o input cho 16 features. 
    # ƒê·ªÉ giao di·ªán ƒë·∫πp, ta nh√≥m c√°c feature quan tr·ªçng l√™n ƒë·∫ßu
    
    # Nh√≥m 1: Feature g·ªëc quan tr·ªçng
    st.markdown("**Ch·ªâ s·ªë c∆° b·∫£n:**")
    input_data['Sum_Quantity'] = st.number_input("T·ªïng s·ªë l∆∞·ª£ng h√†ng (Sum_Quantity)", value=100.0)
    input_data['Sum_TotalPrice'] = st.number_input("T·ªïng chi ti√™u (Sum_TotalPrice)", value=500.0)
    input_data['Count_Invoice'] = st.number_input("S·ªë l·∫ßn mua (Count_Invoice)", value=5.0)
    input_data['Count_Stock'] = st.number_input("S·ªë lo·∫°i h√†ng (Count_Stock)", value=10.0)
    input_data['Mean_UnitPrice'] = st.number_input("ƒê∆°n gi√° trung b√¨nh (Mean_UnitPrice)", value=5.0)
    
    # Nh√≥m 2: C√°c feature t√≠nh to√°n (cho v√†o expander ƒë·ªÉ g·ªçn)
    with st.expander("C√°c ch·ªâ s·ªë n√¢ng cao (M·ªü r·ªông)"):
        # L·∫•y c√°c feature c√≤n l·∫°i trong feature_names m√† ch∆∞a c√≥ input
        remaining_features = [f for f in feature_names if f not in input_data]
        for f in remaining_features:
            input_data[f] = st.number_input(f"{f}", value=0.0)

    btn_predict = st.button("Ph√¢n t√≠ch ngay", type="primary")

with col2:
    if btn_predict:
        # --- B∆Ø·ªöC 1: T·∫†O DATAFRAME ---
        # ƒê·∫£m b·∫£o th·ª© t·ª± c·ªôt ƒë√∫ng y h·ªát l√∫c train
        df_input = pd.DataFrame([input_data])
        df_input = df_input[feature_names] # Reorder columns
        
        # --- B∆Ø·ªöC 2: X·ª¨ L√ù D·ªÆ LI·ªÜU (PREPROCESSING) ---
        # Logic n√†y m√¥ ph·ªèng l·∫°i class FeatureEngineer trong cluster_lib.py
        
        # 2.1 Box-Cox Transformation
        # L∆∞u √Ω: Box-cox c·∫ßn d·ªØ li·ªáu d∆∞∆°ng. Ta d√πng np.log1p (log(x+1)) 
        # nh∆∞ m·ªôt s·ª± thay th·∫ø an to√†n v√† g·∫ßn t∆∞∆°ng ƒë∆∞∆°ng cho Web App ƒë·ªÉ tr√°nh l·ªói s·ªë √¢m.
        # (Trong th·ª±c t·∫ø production, b·∫°n c·∫ßn l∆∞u lambda c·ªßa boxcox t·ª´ng c·ªôt ƒë·ªÉ transform ch√≠nh x√°c 100%)
        df_transformed = np.log1p(np.abs(df_input))
        
        # 2.2 Scaling
        # N·∫øu kh√¥ng c√≥ scaler x·ªãn, b∆∞·ªõc n√†y ch·ªâ mang t√≠nh t∆∞·ª£ng tr∆∞ng
        if scaler:
            try:
                # N·∫øu scaler ch∆∞a fit (tr∆∞·ªùng h·ª£p t·∫°o m·ªõi), ta fit t·∫°m (kh√¥ng khuy·∫øn kh√≠ch)
                # N·∫øu scaler load t·ª´ file, n√≥ s·∫Ω transform ƒë√∫ng
                if hasattr(scaler, 'mean_'): 
                    X_scaled = scaler.transform(df_transformed)
                else:
                    X_scaled = scaler.fit_transform(df_transformed)
            except:
                 X_scaled = df_transformed.values # Fallback
        else:
            X_scaled = df_transformed.values

        # 2.3 PCA Transform
        if pca:
            X_pca = pca.transform(X_scaled)
        else:
            X_pca = X_scaled

        # --- B∆Ø·ªöC 3: D·ª∞ ƒêO√ÅN ---
        cluster_id = kmeans.predict(X_pca)[0]
        
        # --- B∆Ø·ªöC 4: HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
        st.success(f"K·∫øt qu·∫£ ph√¢n lo·∫°i: **{cluster_desc.get(cluster_id, f'Cluster {cluster_id}')}**")
        
        # --- B∆Ø·ªöC 5: BI·ªÇU ƒê·ªí RADAR ---
        st.subheader("H·ªì s∆° kh√°ch h√†ng")
        
        # Ch·ªçn 5 ch·ªâ s·ªë quan tr·ªçng nh·∫•t ƒë·ªÉ v·∫Ω
        radar_cols = ['Sum_Quantity', 'Sum_TotalPrice', 'Count_Invoice', 'Count_Stock', 'Mean_UnitPrice']
        radar_vals = [input_data[c] for c in radar_cols]
        
        # Chu·∫©n h√≥a min-max (gi·∫£ l·∫≠p) ƒë·ªÉ v·∫Ω l√™n bi·ªÉu ƒë·ªì cho ƒë·∫πp
        # V√¨ gi√° tr·ªã ti·ªÅn r·∫•t to so v·ªõi s·ªë l·∫ßn mua, ta d√πng log ƒë·ªÉ v·∫Ω
        radar_vals_log = np.log1p(radar_vals)
        
        df_radar = pd.DataFrame(dict(
            r=radar_vals_log,
            theta=radar_cols
        ))
        
        fig = px.line_polar(df_radar, r='r', theta='theta', line_close=True)
        fig.update_traces(fill='toself')
        st.plotly_chart(fig)

    else:
        st.info("üëà Nh·∫≠p th√¥ng tin b√™n tr√°i ƒë·ªÉ xem kh√°ch h√†ng thu·ªôc nh√≥m n√†o.")